# -*- coding: utf-8 -*-
"""StreamLit Deployment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14Q-0-0MrD1_AzSq2IpWDhwAmGEG0ND0l
"""

'''
Project: MNIST Image Generator Web App

File Structure:

mnist_generator/
├── app.py
├── requirements.txt
└── mnist.pth   # pre-trained generator model state_dict

Instructions:
- Push this folder to a GitHub repo
- Connect the repo on Streamlit Cloud for automatic deployment

'''

# app.py
import streamlit as st
import torch
import torch.nn as nn
import numpy as np

device = torch.device('cpu')  # Change to 'cuda' if you want GPU on local

num_classes = 10
latent_dim = 20

# CNN-based Conditional VAE model (same as training script)
class Encoder(nn.Module):
    def __init__(self, latent_dim, num_classes):
        super().__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(1 + num_classes, 32, 4, 2, 1),  # 28x28 -> 14x14
            nn.ReLU(),
            nn.Conv2d(32, 64, 4, 2, 1),               # 14x14 -> 7x7
            nn.ReLU(),
            nn.Flatten()
        )
        self.fc_mu = nn.Linear(64 * 7 * 7, latent_dim)
        self.fc_logvar = nn.Linear(64 * 7 * 7, latent_dim)

    def forward(self, x):
        h = self.conv(x)
        mu = self.fc_mu(h)
        logvar = self.fc_logvar(h)
        return mu, logvar

class Decoder(nn.Module):
    def __init__(self, latent_dim, num_classes):
        super().__init__()
        self.fc = nn.Linear(latent_dim + num_classes, 64 * 7 * 7)
        self.deconv = nn.Sequential(
            nn.ReLU(),
            nn.Unflatten(1, (64, 7, 7)),
            nn.ConvTranspose2d(64, 32, 4, 2, 1),
            nn.ReLU(),
            nn.ConvTranspose2d(32, 1, 4, 2, 1),
            nn.Sigmoid()
        )

    def forward(self, z, labels):
        z = torch.cat([z, labels], dim=1)
        h = self.fc(z)
        x_recon = self.deconv(h)
        return x_recon

class ConditionalVAE(nn.Module):
    def __init__(self, latent_dim=20, num_classes=10):
        super().__init__()
        self.encoder = Encoder(latent_dim, num_classes)
        self.decoder = Decoder(latent_dim, num_classes)

    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std

    def forward(self, x, labels):
        mu, logvar = self.encoder(x)
        z = self.reparameterize(mu, logvar)
        recon_x = self.decoder(z, labels)
        return recon_x, mu, logvar

@st.cache_resource
def load_model():
    model = ConditionalVAE(latent_dim, num_classes)
    model.load_state_dict(torch.load("cvae_cnn.pth", map_location=device))
    model.eval()
    return model

def generate_digit_images(model, digit, num_images=5):
    model.to(device)
    model.eval()
    digit_tensor = torch.tensor([digit]).to(device)
    label_onehot = torch.nn.functional.one_hot(digit_tensor, num_classes=num_classes).float()
    label_onehot = label_onehot.to(device)

    images = []
    for _ in range(num_images):
        z = torch.randn(1, latent_dim).to(device)
        with torch.no_grad():
            generated = model.decoder(z, label_onehot)
        img = generated.squeeze(0).cpu().numpy()  # shape: (1,28,28)
        img = img.transpose(1, 2, 0).squeeze()   # shape: (28,28)
        images.append(img)
    return images

st.set_page_config(page_title="VAE Digit Generator", layout="centered")
st.title("Handwritten Digit Generator")
st.markdown("Select a digit (0-9) and generate handwritten images conditioned on it.")

digit = st.selectbox("Choose digit:", list(range(10)))

if st.button("Generate 5 Images"):
    model = load_model()
    images = generate_digit_images(model, digit)
    st.markdown(f"### Generated Images for digit `{digit}`")

    cols = st.columns(5)
    for i, img in enumerate(images):
        with cols[i]:
            st.image(img, width=100, clamp=True, caption=f"#{i+1}")


# requirements.txt
"""
streamlit
torch
torchvision
matplotlib
Pillow
numpy

"""